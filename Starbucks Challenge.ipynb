{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data set contains simulated data that mimics customer behavior on the Starbucks rewards mobile app. Once every few days, Starbucks sends out an offer to users of the mobile app. An offer can be merely an advertisement for a drink or an actual offer such as a discount or BOGO (buy one get one free). Some users might not receive any offer during certain weeks.\n",
    "\n",
    "Not all users receive the same offer, and that is the challenge to solve with this data set.\n",
    "\n",
    "Your task is to combine transaction, demographic and offer data to determine which demographic groups respond best to which offer type. This data set is a simplified version of the real Starbucks app because the underlying simulator only has one product whereas Starbucks actually sells dozens of products.\n",
    "\n",
    "Every offer has a validity period before the offer expires. As an example, a BOGO offer might be valid for only 5 days. You'll see in the data set that informational offers have a validity period even though these ads are merely providing information about a product; for example, if an informational offer has 7 days of validity, you can assume the customer is feeling the influence of the offer for 7 days after receiving the advertisement.\n",
    "\n",
    "You'll be given transactional data showing user purchases made on the app including the timestamp of purchase and the amount of money spent on a purchase. This transactional data also has a record for each offer that a user receives as well as a record for when a user actually views the offer. There are also records for when a user completes an offer.\n",
    "\n",
    "Keep in mind as well that someone using the app might make a purchase through the app without having received an offer or seen an offer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To give an example, a user could receive a discount offer buy 10 dollars get 2 off on Monday. The offer is valid for 10 days from receipt. If the customer accumulates at least 10 dollars in purchases during the validity period, the customer completes the offer.\n",
    "\n",
    "However, there are a few things to watch out for in this data set. Customers do not opt into the offers that they receive; in other words, a user can receive an offer, never actually view the offer, and still complete the offer. For example, a user might receive the \"buy 10 dollars get 2 dollars off offer\", but the user never opens the offer during the 10 day validity period. The customer spends 15 dollars during those ten days. There will be an offer completion record in the data set; however, the customer was not influenced by the offer because the customer never viewed the offer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This makes data cleaning especially important and tricky.\n",
    "\n",
    "You'll also want to take into account that some demographic groups will make purchases even if they don't receive an offer. From a business perspective, if a customer is going to make a 10 dollar purchase without an offer anyway, you wouldn't want to send a buy 10 dollars get 2 dollars off offer. You'll want to try to assess what a certain demographic group will buy when not receiving any offers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Remark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because this is a capstone project, you are free to analyze the data any way you see fit. For example, you could build a machine learning model that predicts how much someone will spend based on demographics and offer type. Or you could build a model that predicts whether or not someone will respond to an offer. Or, you don't need to build a machine learning model at all. You could develop a set of heuristics that determine what offer you should send to each customer (i.e., 75 percent of women customers who were 35 years old responded to offer A vs 40 percent from the same demographic to offer B, so send offer A)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is contained in three files:\n",
    "\n",
    "portfolio.json - containing offer ids and meta data about each offer (duration, type, etc.)\n",
    "profile.json - demographic data for each customer\n",
    "transcript.json - records for transactions, offers received, offers viewed, and offers completed\n",
    "Here is the schema and explanation of each variable in the files:\n",
    "\n",
    "portfolio.json\n",
    "\n",
    "id (string) - offer id\n",
    "offer_type (string) - type of offer ie BOGO, discount, informational\n",
    "difficulty (int) - minimum required spend to complete an offer\n",
    "reward (int) - reward given for completing an offer\n",
    "duration (int) - time for offer to be open, in days\n",
    "channels (list of strings)\n",
    "profile.json\n",
    "\n",
    "age (int) - age of the customer\n",
    "became_member_on (int) - date when customer created an app account\n",
    "gender (str) - gender of the customer (note some entries contain 'O' for other rather than M or F)\n",
    "id (str) - customer id\n",
    "income (float) - customer's income\n",
    "transcript.json\n",
    "\n",
    "event (str) - record description (ie transaction, offer received, offer viewed, etc.)\n",
    "person (str) - customer id\n",
    "time (int) - time in hours since start of test. The data begins at time t=0\n",
    "value - (dict of strings) - either an offer id or transaction amount depending on the record\n",
    "Note: If you are using the workspace, you will need to go to the terminal and run the command conda update pandas before reading in the files. This is because the version of pandas in the workspace cannot read in the transcript.json file correctly, but the newest version of pandas can. You can access the termnal from the orange icon in the top left of this notebook.\n",
    "\n",
    "You can see how to access the terminal and how the install works using the two images below. First you need to access the terminal:\n",
    "\n",
    "\n",
    "\n",
    "Then you will want to run the above command:\n",
    "\n",
    "\n",
    "\n",
    "Finally, when you enter back into the notebook (use the jupyter icon again), you should be able to run the below cell without any errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be exploring the Starbuckâ€™s Dataset which simulates how people make purchasing decisions and how those decisions are influenced by promotional offers.\n",
    "\n",
    "There are three offers_types that can be sent: buy-one-get-one (BOGO), discount, and informational.\n",
    "\n",
    "We will create a model that can predict behaviour of customer.\n",
    "\n",
    "We will analyse the data in the Exploratory Data Analysis part of this section and answer the following bussiness questions related to customer buying behaviour.\n",
    "\n",
    "What is the Gender, Age and Income Distribution of Starbucks Customers?\n",
    "How many customers enrolled yearly?\n",
    "What is the average age of Starbucks Customers?\n",
    "What is the average Income of Starbucks Customers?\n",
    "Which gender has the highest yearly membership?\n",
    "Which gender has the highest annual income?\n",
    "What is the distribution of event in transcripts?\n",
    "What is the percent of trasactions and offers in the event?\n",
    "What are the types of offers : received, views, completed?\n",
    "What is the Income Distribution for the Offer Events?\n",
    "What is the highest completed offer?\n",
    "What is the lowest completed offer?\n",
    "To compare different classification algorithms we will use lazypredict library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lazypredict in c:\\users\\henry\\anaconda3\\lib\\site-packages (0.2.9)\n",
      "Requirement already satisfied: scikit-learn==0.23.1 in c:\\users\\henry\\anaconda3\\lib\\site-packages (from lazypredict) (0.23.1)\n",
      "Requirement already satisfied: scipy==1.5.4 in c:\\users\\henry\\anaconda3\\lib\\site-packages (from lazypredict) (1.5.4)\n",
      "Requirement already satisfied: lightgbm==2.3.1 in c:\\users\\henry\\anaconda3\\lib\\site-packages (from lazypredict) (2.3.1)\n",
      "Requirement already satisfied: numpy==1.19.1 in c:\\users\\henry\\anaconda3\\lib\\site-packages (from lazypredict) (1.19.1)\n",
      "Requirement already satisfied: xgboost==1.1.1 in c:\\users\\henry\\anaconda3\\lib\\site-packages (from lazypredict) (1.1.1)\n",
      "Requirement already satisfied: joblib==1.0.0 in c:\\users\\henry\\anaconda3\\lib\\site-packages (from lazypredict) (1.0.0)\n",
      "Requirement already satisfied: PyYAML==5.3.1 in c:\\users\\henry\\anaconda3\\lib\\site-packages (from lazypredict) (5.3.1)\n",
      "Requirement already satisfied: tqdm==4.56.0 in c:\\users\\henry\\anaconda3\\lib\\site-packages (from lazypredict) (4.56.0)\n",
      "Requirement already satisfied: click==7.1.2 in c:\\users\\henry\\anaconda3\\lib\\site-packages (from lazypredict) (7.1.2)\n",
      "Requirement already satisfied: pytest==5.4.3 in c:\\users\\henry\\anaconda3\\lib\\site-packages (from lazypredict) (5.4.3)\n",
      "Requirement already satisfied: pandas==1.0.5 in c:\\users\\henry\\anaconda3\\lib\\site-packages (from lazypredict) (1.0.5)\n",
      "Requirement already satisfied: six==1.15.0 in c:\\users\\henry\\anaconda3\\lib\\site-packages (from lazypredict) (1.15.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\henry\\anaconda3\\lib\\site-packages (from scikit-learn==0.23.1->lazypredict) (2.1.0)\n",
      "Requirement already satisfied: pluggy<1.0,>=0.12 in c:\\users\\henry\\anaconda3\\lib\\site-packages (from pytest==5.4.3->lazypredict) (0.13.1)\n",
      "Requirement already satisfied: py>=1.5.0 in c:\\users\\henry\\anaconda3\\lib\\site-packages (from pytest==5.4.3->lazypredict) (1.9.0)\n",
      "Requirement already satisfied: atomicwrites>=1.0; sys_platform == \"win32\" in c:\\users\\henry\\anaconda3\\lib\\site-packages (from pytest==5.4.3->lazypredict) (1.4.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in c:\\users\\henry\\anaconda3\\lib\\site-packages (from pytest==5.4.3->lazypredict) (8.6.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\henry\\anaconda3\\lib\\site-packages (from pytest==5.4.3->lazypredict) (20.4)\n",
      "Requirement already satisfied: colorama; sys_platform == \"win32\" in c:\\users\\henry\\anaconda3\\lib\\site-packages (from pytest==5.4.3->lazypredict) (0.4.4)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\henry\\anaconda3\\lib\\site-packages (from pytest==5.4.3->lazypredict) (0.2.5)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\henry\\anaconda3\\lib\\site-packages (from pytest==5.4.3->lazypredict) (20.3.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\henry\\anaconda3\\lib\\site-packages (from pandas==1.0.5->lazypredict) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\henry\\anaconda3\\lib\\site-packages (from pandas==1.0.5->lazypredict) (2.8.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\henry\\anaconda3\\lib\\site-packages (from packaging->pytest==5.4.3->lazypredict) (2.4.7)\n"
     ]
    }
   ],
   "source": [
    "# Install lazypredict library\n",
    "!pip install lazypredict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Henry\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.utils.testing module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.utils. Anything that cannot be imported from sklearn.utils is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "ename": "URLError",
     "evalue": "<urlopen error [Errno 11001] getaddrinfo failed>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mdo_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1349\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m                 h.request(req.get_method(), req.selector, req.data, headers,\n\u001b[0m\u001b[0;32m   1351\u001b[0m                           encode_chunked=req.has_header('Transfer-encoding'))\n",
      "\u001b[1;32m~\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1254\u001b[0m         \u001b[1;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1255\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1300\u001b[0m             \u001b[0mbody\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'body'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1301\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mendheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1249\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1250\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1009\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1010\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1011\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    949\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 950\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    951\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1416\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1417\u001b[1;33m             \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    920\u001b[0m         \u001b[1;34m\"\"\"Connect to the host and port specified in __init__.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 921\u001b[1;33m         self.sock = self._create_connection(\n\u001b[0m\u001b[0;32m    922\u001b[0m             (self.host,self.port), self.timeout, self.source_address)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address)\u001b[0m\n\u001b[0;32m    786\u001b[0m     \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgetaddrinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSOCK_STREAM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    788\u001b[0m         \u001b[0maf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mgetaddrinfo\u001b[1;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[0;32m    917\u001b[0m     \u001b[0maddrlist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 918\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_socket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    919\u001b[0m         \u001b[0maf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mgaierror\u001b[0m: [Errno 11001] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-d433b2e24c1c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# read in the json files\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mportfolio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'https://raw.githubusercontent.com/bilgin-kocak/starbucks-customer-capstone-project/master/data/portfolio.json'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morient\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'records'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mprofile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'https://raw.githubusercontent.com/bilgin-kocak/starbucks-customer-capstone-project/master/data/profile.json'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morient\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'records'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mtranscript\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'https://raw.githubusercontent.com/bilgin-kocak/starbucks-customer-capstone-project/master/data/transcript.json'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morient\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'records'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    212\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\json\\_json.py\u001b[0m in \u001b[0;36mread_json\u001b[1;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, lines, chunksize, compression)\u001b[0m\n\u001b[0;32m    582\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m     \u001b[0mcompression\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minfer_compression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 584\u001b[1;33m     filepath_or_buffer, _, compression, should_close = get_filepath_or_buffer(\n\u001b[0m\u001b[0;32m    585\u001b[0m         \u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    586\u001b[0m     )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_filepath_or_buffer\u001b[1;34m(filepath_or_buffer, encoding, compression, mode)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 172\u001b[1;33m         \u001b[0mreq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m         \u001b[0mcontent_encoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Content-Encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcontent_encoding\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"gzip\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m         \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maudit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'urllib.Request'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 525\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    526\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m         \u001b[1;31m# post-process response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    541\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0m\u001b[0;32m    543\u001b[0m                                   '_open', req)\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    500\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 502\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    503\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttps_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1392\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mhttps_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1393\u001b[1;33m             return self.do_open(http.client.HTTPSConnection, req,\n\u001b[0m\u001b[0;32m   1394\u001b[0m                 context=self._context, check_hostname=self._check_hostname)\n\u001b[0;32m   1395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mdo_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1351\u001b[0m                           encode_chunked=req.has_header('Transfer-encoding'))\n\u001b[0;32m   1352\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# timeout error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1353\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1354\u001b[0m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1355\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mURLError\u001b[0m: <urlopen error [Errno 11001] getaddrinfo failed>"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "import seaborn as sns\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "\n",
    "# read in the json files\n",
    "portfolio = pd.read_json('https://raw.githubusercontent.com/bilgin-kocak/starbucks-customer-capstone-project/master/data/portfolio.json', orient='records', lines=True)\n",
    "profile = pd.read_json('https://raw.githubusercontent.com/bilgin-kocak/starbucks-customer-capstone-project/master/data/profile.json', orient='records', lines=True)\n",
    "transcript = pd.read_json('https://raw.githubusercontent.com/bilgin-kocak/starbucks-customer-capstone-project/master/data/transcript.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we will deal with missing values and extreme values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only profile dataframe has missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile['age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_counts = profile['age'].value_counts()\n",
    "age_counts.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will drop row in profile dataframe if age is 118, gender and income value is nan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = profile[~((profile.age == 118) & (profile.gender.isnull()) & (profile.income.isnull()))]\n",
    "profile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile['became_member_on'] = pd.to_datetime(profile.became_member_on, format = '%Y%m%d')\n",
    "profile['start_year'] = profile.became_member_on.dt.year\n",
    "profile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode : channels column\n",
    "channels = portfolio[\"channels\"].str.join(sep=\"*\").str.get_dummies(sep=\"*\")\n",
    "    \n",
    "# One-hot encode : offer_type column\n",
    "offer_type = pd.get_dummies(portfolio['offer_type'])\n",
    "    \n",
    "# Concat one-hot into a portfolio_df\n",
    "portfolio_df = pd.concat([portfolio, channels, offer_type], axis=1, sort=False)\n",
    "\n",
    "# Remove channels and offer_type\n",
    "portfolio = portfolio_df.drop(['channels'], axis=1)\n",
    "portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript['value'].apply(lambda x: x.keys()).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 3 different keys in value column. These are offer_id, amount and reward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript['offer_id'] = transcript['value'].apply(lambda x: x['offer id'] if 'offer id' in x.keys() else x['offer_id'] if \"offer_id\" in x.keys() else np.nan)\n",
    "transcript['amount'] = transcript['value'].apply(lambda x: x['amount'] if 'amount' in x.keys() else np.nan)\n",
    "transcript['reward'] = transcript['value'].apply(lambda x: x['reward'] if 'reward' in x.keys() else np.nan)\n",
    "transcript.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript.drop(columns=['value'], inplace=True)\n",
    "transcript.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the transcript and profile dataframes on customer_id column\n",
    "transcript = transcript.merge(profile, on=['customer_id'])\n",
    "# merge the transcript and portfolio  on offer_id column using left join\n",
    "# To maintain all the offer_ids from the transcript column\n",
    "transcript = transcript.merge(portfolio, on=['offer_id'], how='left')\n",
    "transcript.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label Encoding the category columns- \n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "#label encoding - offer_id (10 different IDs) from the portfolio data set\n",
    "le1 = preprocessing.LabelEncoder()\n",
    "le1.fit(portfolio.offer_id)\n",
    "transcript['offer_id'] = le1.fit_transform(transcript['offer_id'].astype(str))\n",
    "\n",
    "\n",
    "#label encoding - offer_type from the portfolio data set (3 different types, bogo-discount-informational)\n",
    "le2 = preprocessing.LabelEncoder()\n",
    "le2.fit(portfolio.offer_type)\n",
    "transcript['offer_type'] = le2.fit_transform(transcript['offer_type'].astype(str))\n",
    "\n",
    "\n",
    "# label encoding for gender from the profile data set(4 different types, male-female-other)\n",
    "le3 = preprocessing.LabelEncoder()\n",
    "le3.fit(profile.gender)\n",
    "transcript['gender'] = le3.fit_transform(transcript['gender'].astype(str))\n",
    "\n",
    "transcript.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To retrive its original value we can use its inverse function\n",
    "le3.inverse_transform([0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le4 = preprocessing.LabelEncoder()\n",
    "le4.fit(profile.customer_id)\n",
    "transcript['customer_id'] = le3.fit_transform(transcript['customer_id'].astype(str))\n",
    "transcript.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript.customer_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate the three offer columns from the transaction column\n",
    "transaction_df = transcript[transcript.event == \"transaction\"]\n",
    "offers_df = transcript[transcript.event != \"transaction\"]\n",
    "offers_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis:\n",
    "What is the Gender, Age and Income Distribution of Starbucks Customers?\n",
    "How many customers enrolled yearly?\n",
    "What is the average age of Starbucks Customers?\n",
    "What is the average Income of Starbucks Customers?\n",
    "Which gender has the highest yearly membership?\n",
    "Which gender has the highest annual income?\n",
    "What is the distribution of event in transcripts?\n",
    "What is the percent of trasactions and offers in the event?\n",
    "What are the types of offers : received, views, completed?\n",
    "What is the Income Distribution for the Offer Events?\n",
    "What is the highest completed offer?\n",
    "What is the lowest completed offer?\n",
    "Q1: What is the Gender, Age and Income Distribution of Starbucks Customers?\n",
    "\n",
    "Q2: How many customers enrolled yearly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Subplots for distribution based on Gender,Age,Income and start year of membership for the cleaned Profile data\n",
    "fig, ax = plt.subplots(2, 2, figsize=(13, 12))\n",
    "fig.suptitle('Demographics of Customer Data of Starbucks', fontsize=15, weight='bold')\n",
    "\n",
    "# GENDER BASED SUBPLOT\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.hist(profile['gender']);\n",
    "plt.style.use('seaborn');\n",
    "plt.title('Gender Distribution of Starbucks Customers');\n",
    "plt.xlabel(\"Gender\");\n",
    "plt.ylabel(\"Frequency\");\n",
    "\n",
    "\n",
    "# AGE BASED SUBPLOT\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.hist(profile['age']);\n",
    "plt.style.use('seaborn')\n",
    "plt.title(\"Age Distribution of Starbucks Customers\" );\n",
    "plt.xlabel(\"Age\");\n",
    "plt.ylabel(\"Frequency\");\n",
    "\n",
    "# INCOME BASED  SUBPLOT\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.hist(profile['income'] * 1E-3 );\n",
    "plt.style.use('seaborn')\n",
    "plt.title(\"Income Distribution of Starbucks Customers\");\n",
    "plt.xlabel(\"Income\");\n",
    "plt.ylabel(\"Frequency\");\n",
    "\n",
    "\n",
    "# BECAME A MEMBER OF STARBUCKS ON(YEAR) SUBPLOT\n",
    "plt.subplot(2, 2, 4)\n",
    "profile[\"start_year\"].value_counts().plot(kind = 'bar'); \n",
    "plt.style.use('seaborn')\n",
    "plt.title(\"Yearly Membership of Starbucks Customers\");\n",
    "plt.xlabel(\"Yearly Membership\");\n",
    "plt.ylabel(\"Frequency\");\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3: What is the average age of Starbucks Customers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_age = profile['age'].describe()['mean']\n",
    "print(f\"The average age of starbucks customers: {avg_age:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4: What is the average Income of Starbucks Customers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_income = profile['income'].describe()['mean']\n",
    "print(f\"The average income of starbucks customers: {avg_income:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5: Which gender has the highest yearly membership?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby start_year and gender to plot a graph\n",
    "membership_year = profile.groupby(['start_year', 'gender'])[\"income\"].count().reset_index()\n",
    "highest_gender_index = (membership_year.groupby('start_year').idxmax().income)\n",
    "membership_year.rename(columns={'income':'number of membership'}, inplace=True)\n",
    "membership_year.loc[highest_gender_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot a bar graph for membership program as a function of gender \n",
    "plt.figure(figsize=(15, 5))\n",
    "sns.barplot(x='start_year', y='number of membership', hue='gender', data=membership_year);\n",
    "plt.xlabel('Membership Start Year',fontsize = 12);\n",
    "plt.ylabel('Count',fontsize = 12);\n",
    "plt.title(\"Gender distribution of yearly membership\", fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6: Which gender has the highest annual income?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_income = profile.groupby('gender')['income'].mean()\n",
    "avg_income"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7: What is the distribution of event in transcripts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(transcript['event'])\n",
    "plt.title('Number of events In Transcripts')\n",
    "plt.ylabel('Number of Transcripts')\n",
    "plt.xlabel('Transcript type')\n",
    "plt.xticks(rotation = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8: What is the percent of trasactions and offers in the event?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_percentage = len(transcript[transcript['event']=='transaction'])/len(transcript)\n",
    "offer_percentage = len(transcript[transcript['event']!='transaction'])/len(transcript)\n",
    "\n",
    "print(f'The percentage of transaction in all events: {transaction_percentage*100:.2f}')\n",
    "print(f'The percentage of offer in all events: {offer_percentage*100:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q9: What are the types of offers : received, views, completed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offers_df.event.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offer_received = offers_df[offers_df[\"event\"] == \"offer received\"]\n",
    "offer_viewed = offers_df[offers_df[\"event\"]== \"offer viewed\"]\n",
    "offer_completed = offers_df[offers_df[\"event\"] == \"offer completed\"]\n",
    "\n",
    "# Visualize distribution of membership days grouped by success\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "fig.suptitle('Offer types : received, viewed and completed', fontsize=15, weight='bold')\n",
    "\n",
    "# Subplot for bogo offers\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.countplot(x=offer_received['offer_type'])\n",
    "plt.title('Number of types of offers received ', fontsize=13)\n",
    "plt.xlabel('Offer Received')\n",
    "plt.xticks(rotation = 45, fontsize=13)\n",
    "\n",
    "\n",
    "# Subplot for discount offers\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.countplot(x=offer_viewed['offer_type'])\n",
    "plt.title('Number of Viewed Promotions for each Offer', fontsize=13)\n",
    "plt.xlabel('Offer Viewed')\n",
    "plt.xticks(rotation = 45, fontsize=13)\n",
    "\n",
    "# Subplot for informational offers\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.countplot(x=offer_completed['offer_type'])\n",
    "plt.title('Number of Viewed Promotions for each Offer', fontsize=13)\n",
    "plt.xlabel('Offer Completed')\n",
    "plt.xticks(rotation = 45, fontsize=13)\n",
    "plt.show()\n",
    "i = 0\n",
    "for offer_type in le2.inverse_transform([0, 1, 2]):\n",
    "    print(f\"{i} : {offer_type}\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q10: What is the Income Distribution for the Offer Events?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Income group Column cleaning by  segregation\n",
    "offers_df['income_groups'] = pd.cut(x=profile[\"income\"],\n",
    "                                    bins=[30000, 40000, 50000, 60000, 70000, 80000, 90000, 100000, 110000,  120000],\n",
    "                                   labels =['30-40K','40-50K','50-60K','60-70K','70-80K','80-90K','90-100K','100-110K','110-120K'])\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.countplot(x=offers_df['income_groups'], hue=\"event\", data=offers_df)\n",
    "plt.title(\"Income Distribution for the Offer Events\")\n",
    "plt.ylabel('Total')\n",
    "plt.xlabel('Income ')\n",
    "plt.xticks(rotation = 30)\n",
    "plt.legend(title='Offer Event')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q11: What is the highest completed offer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_completion = offer_completed.offer_id.value_counts().values[0]\n",
    "max_comp_offer_id = offer_completed.offer_id.value_counts().index[0]\n",
    "print(f\"Number of Completion: {max_completion}\")\n",
    "print(f\"offer_id with maximum offers completed:{max_comp_offer_id}\")\n",
    "print(f\"Original offer_id with maximum offers completed: {le1.inverse_transform([max_comp_offer_id])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q12: What is the lowest completed offer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_completion = offer_completed.offer_id.value_counts().values[-1]\n",
    "min_comp_offer_id = offer_completed.offer_id.value_counts().index[-1]\n",
    "print(f\"Number of Completion: {min_completion}\")\n",
    "print(f\"offer_id with maximum offers completed:{min_comp_offer_id}\")\n",
    "print(f\"Original offer_id with maximum offers completed: {le1.inverse_transform([min_comp_offer_id])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.Data Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics:\n",
    "It is a simple classification problem therefore, we will use accuracy to evaluate models.\n",
    "Comapre the correct predictions and total number of predicitons to determine the accuracy of the model and choose the best.\n",
    "In order to compare other models we will use lazypredict library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping these columns because with null values, datetime,object,category datatypes\n",
    "cols_to_drop = ['income_groups','amount','became_member_on' ,'event','reward_x']\n",
    "offers_df = offers_df.drop(columns= cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offers_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offers_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning (Classification)\n",
    "The target column is offer_type. It will help to predict the correct offer_type to send to each customer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = offers_df.drop(columns=['offer_type', 'customer_id', 'offer_id'])\n",
    "y = offers_df.offer_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(offers_df.offer_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2,random_state =42)\n",
    "\n",
    "clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "models,predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evalute the model accuracy\n",
    "Let's evalaute AdaBoostClassifier model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Train Data Size: {X_train.shape[0]}')\n",
    "print(f'Test Data Size: {X_test.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select randomly one offer from test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.iloc[12535,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.iloc[12535]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le2.inverse_transform([0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_customer_data = list(X_test.iloc[12535,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "clf = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(np.reshape(np.array(random_customer_data),(1,-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has correctly predicted that the customer will likely respond discount offer type with an accuracy of 100 %. Hence our model has good accuracy for prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.Conclusion\n",
    "Different segments of customers react to offers differently.\n",
    "\n",
    "The average age of starbucks customers is 54.39.\n",
    "\n",
    "The count of male customers in low-income level is slightly higher than that of female.\n",
    "\n",
    "the average salary of female is greater than male average salary, female spend less on starbucks than male.\n",
    "\n",
    "Starbucks has more of the young people than those of the aged once.\n",
    "\n",
    "The result of the offer_type was prediced succesfully by training a supervised classifier.\n",
    "\n",
    "Improvement:\n",
    "By using more data we can select the best classification algorithm. For the given data, below classifier model give best result.\n",
    "\n",
    "AdaBoostClassifier\n",
    "BaggingClassifier\n",
    "XGBClassifier\n",
    "SVC\n",
    "SGDClassifier\n",
    "RidgeClassifierCV\n",
    "RidgeClassifier\n",
    "RandomForestClassifier\n",
    "QuadraticDiscriminantAnalysis\n",
    "Perceptron\n",
    "PassiveAggressiveClassifier\n",
    "NuSVC\n",
    "NearestCentroid\n",
    "LogisticRegression\n",
    "LinearSVC\n",
    "LinearDiscriminantAnalysis\n",
    "KNeighborsClassifier\n",
    "GaussianNB\n",
    "ExtraTreesClassifier\n",
    "ExtraTreeClassifier\n",
    "DecisionTreeClassifier\n",
    "CalibratedClassifierCV\n",
    "BernoulliNB\n",
    "LGBMClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.Results\n",
    "Customers are attracted to BOGO and Discount offers more as compared to Informational Offers. The buying behaviour of a customer are independent of its annual income.\n",
    "\n",
    "Starbucks have more male customers than females and other gender.\n",
    "\n",
    "Most of the classification model give best results for the given data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
